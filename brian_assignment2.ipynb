{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Image Dataset structure and image transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "class ImageDataSet(Dataset):\n",
    "    def __init__(self, t_cells, tumors, transform):\n",
    "        self.file_names = t_cells + tumors\n",
    "        self.labels = [1]*len(t_cells) + [0]*len(tumors)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.file_names[index]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #Offically used by Pytorch\n",
    "])\n",
    "\n",
    "t_cells = []\n",
    "invasive_tumors = []\n",
    "\n",
    "for (dir_path, dir_names, file_names) in os.walk('Images/100'):\n",
    "    parent_folder = os.path.basename(dir_path)\n",
    "    if parent_folder in [\"CD4+_T_Cells\", \"Invasive_Tumor\"]:\n",
    "        for file in file_names:\n",
    "            image = cv2.imread(os.path.join(dir_path, file))\n",
    "            if image.shape[0] < 100 and image.shape[1] < 100: #skip the small image, it doesn't give much info\n",
    "                continue\n",
    "            if parent_folder == \"CD4+_T_Cells\":\n",
    "                t_cells.append(os.path.join(dir_path, file))\n",
    "            elif parent_folder == \"Invasive_Tumor\":\n",
    "                invasive_tumors.append(os.path.join(dir_path, file))\n",
    "    \n",
    "dataset = ImageDataSet(t_cells, invasive_tumors, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the (pre-trained) CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #check if the computer has GPU\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)  # 2 classes: Tumor and Immune\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "patience = 10 #for early stopping\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training, validation, and testing sets (70% 15% 15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, temp_idx = train_test_split(list(range(len(dataset))), test_size=0.3, random_state=0)\n",
    "val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=0)\n",
    "\n",
    "train_subset = Subset(dataset, train_idx)\n",
    "val_subset = Subset(dataset, val_idx)\n",
    "test_subset = Subset(dataset, test_idx)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "epoch_no_improvement = 0\n",
    "best_model_parameters = None\n",
    "\n",
    "\n",
    "cnn_training_start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        print(labels)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_val_loss = val_loss/len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model_parameters = model.state_dict()\n",
    "        epoch_no_improvement = 0\n",
    "    else:\n",
    "        epoch_no_improvement += 1\n",
    "        if epoch_no_improvement == patience:\n",
    "            print(f\"No improvement for {patience} epoches. Early stopping.\")\n",
    "            break\n",
    "cnn_training_end = time.time()\n",
    "\n",
    "if best_model_parameters is not None:\n",
    "    model.load_state_dict(best_model_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model performance in testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "# print(classification_report(y_true, y_pred, target_names=[\"Tumor\", \"Immune\"]))\n",
    "pretrained_cnn_accuracy = accuracy_score(y_true, y_pred)\n",
    "print(pretrained_cnn_accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cnn_precision = precision_score(y_true, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [\"Tumor\", \"Immune\"])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.title(\"CNN Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'CNN_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the pre-trained convolutional layers to extract the features from images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "feature_extractor = nn.Sequential(*list(model.children())[:-1]) # remove the last layer\n",
    "feature_extractor.eval()\n",
    "feature_extractor.to(device)\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "test_features = []\n",
    "test_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        output = feature_extractor(images).squeeze()\n",
    "        train_features.append(output.cpu().numpy())\n",
    "        train_labels.append(labels.cpu().numpy())\n",
    "\n",
    "X_train = np.vstack(train_features)\n",
    "y_train = np.hstack(train_labels)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        output = feature_extractor(images).squeeze()\n",
    "        test_features.append(output.cpu().numpy())\n",
    "        test_labels.append(labels.cpu().numpy())\n",
    "\n",
    "X_test = np.vstack(test_features)\n",
    "y_test = np.hstack(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_training_start = time.time()\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_training_end = time.time()\n",
    "\n",
    "svm_accuracy = accuracy_score(y_test, svm.predict(X_test))\n",
    "\n",
    "knn_accuracies = []\n",
    "knn_precision = []\n",
    "for k in range(1, 22, 2): #k = 1 to 21\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    knn_pred = knn.predict(X_test)\n",
    "    knn_accuracies.append(accuracy_score(y_test, knn_pred))\n",
    "    knn_precision.append(precision_score(y_test, knn_pred))\n",
    "\n",
    "knn_accuracies = np.array(knn_accuracies)\n",
    "max_idx = np.argmax(knn_accuracies)\n",
    "best_k = 2*max_idx+1\n",
    "pretrained_knn_best_accuracy = float(knn_accuracies[max_idx])\n",
    "print(f\"Best accuracy when k is {best_k}: {pretrained_knn_best_accuracy:.4f}\")\n",
    "\n",
    "knn_training_start = time.time()\n",
    "best_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "best_knn.fit(X_train, y_train)\n",
    "knn_training_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cm = confusion_matrix(y_test, svm.predict(X_test))\n",
    "svm_precision = precision_score(y_test, svm.predict(X_test))\n",
    "svm_cm_display = ConfusionMatrixDisplay(confusion_matrix = svm_cm, display_labels = [\"Tumor\", \"Immune\"])\n",
    "\n",
    "svm_cm_display.plot()\n",
    "plt.title(\"SVM Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cm = confusion_matrix(y_test, best_knn.predict(X_test))\n",
    "knn_precision = precision_score(y_test, best_knn.predict(X_test))\n",
    "knn_cm_display = ConfusionMatrixDisplay(confusion_matrix = knn_cm, display_labels = [\"Tumor\", \"Immune\"])\n",
    "\n",
    "knn_cm_display.plot()\n",
    "plt.title(f\"{best_k}NN Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = {\"CNN\": cnn_precision, \"SVM\": svm_precision, \"1NN\": knn_precision}\n",
    "plt.bar(precisions.keys(), precisions.values())\n",
    "plt.title(\"Models Precision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = {\"CNN\": pretrained_cnn_accuracy, \"SVM\": svm_accuracy, \"1NN\": pretrained_knn_best_accuracy}\n",
    "plt.bar(accuracies.keys(), accuracies.values())\n",
    "plt.title(\"Models Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CNN training time: {cnn_training_end-cnn_training_start:.2f}s\") #it takes too long. the y scaling would be too large\n",
    "training_times = {\"SVM\": svm_training_end-svm_training_start, \"KNN\": knn_training_end-knn_training_start}\n",
    "plt.bar(training_times.keys(), training_times.values())\n",
    "plt.title(\"Training Time\")\n",
    "plt.ylabel(\"sec\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "cnn_classification_start = time.time()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "cnn_classification_end = time.time()\n",
    "\n",
    "feature_extractor.eval()\n",
    "with torch.no_grad():\n",
    "    svm_classification_start = time.time()\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        output = feature_extractor(images).squeeze()  # shape: (batch_size, feature_dim)\n",
    "        output = output.cpu().numpy()\n",
    "        svm.predict(output)\n",
    "    svm_classification_end = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    knn_classification_start = time.time()\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        output = feature_extractor(images).squeeze()  # shape: (batch_size, feature_dim)\n",
    "        output = output.cpu().numpy()\n",
    "        best_knn.predict(output)\n",
    "    knn_classification_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_time = {\"CNN\": cnn_classification_end-cnn_classification_start, \"SVM\": svm_classification_end-svm_classification_start, \"KNN\": knn_classification_end-knn_classification_start}\n",
    "plt.bar(classification_time.keys(), classification_time.values())\n",
    "plt.title(\"Classification Time\")\n",
    "plt.ylabel(\"sec\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
