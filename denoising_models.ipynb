{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb45f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from resotrmer import Restormer_Denoise\n",
    "from models_DnCNN import DnCNN_Denoiser\n",
    "from denoise_classical import GaussianBlur, MedianBlur\n",
    "import shutil\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import traceback\n",
    "\n",
    "#Turn all the randomisation off to ensure the results of every execution is the same \n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a4b32",
   "metadata": {},
   "source": [
    "### Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9735a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "FOLDER_PATH = \"Images/100\"\n",
    "\n",
    "restomer = Restormer_Denoise(\"blind\")\n",
    "dncnn = DnCNN_Denoiser()\n",
    "\n",
    "denoise_methods = {\n",
    "    \"None\": lambda x:x,\n",
    "    \"Restormer\": restomer.denoise_image,\n",
    "    \"Gaussian_Blur\": GaussianBlur,\n",
    "    \"Median_Blur\": MedianBlur,\n",
    "    \"DnCNN\": dncnn.denoise_image\n",
    "}\n",
    "\n",
    "classification_models = [\"CNN\", \"KNN\", \"SVM\", \"Random Forest\"]\n",
    "\n",
    "models_denoising_accuracies = {model: {denoise_method: -1 for denoise_method in denoise_methods.keys()}  # -1 represent not yet calculated\n",
    "                               for model in classification_models}\n",
    "models_denoising_f1_scores = {model: {denoise_method: -1 for denoise_method in denoise_methods.keys()}  # -1 represent not yet calculated\n",
    "                               for model in classification_models}\n",
    "models_denoising_classification_times = {model: {denoise_method: -1 for denoise_method in denoise_methods.keys()}  # -1 represent not yet calculated\n",
    "                               for model in classification_models}\n",
    "models_denoising_confusion_metrics = {model: {denoise_method: -1 for denoise_method in denoise_methods.keys()}  # -1 represent not yet calculated\n",
    "                               for model in classification_models}\n",
    "\n",
    "def build_transform(denoise_method: str) -> transforms.Compose:\n",
    "    denoise_fn = denoise_methods.get(denoise_method, lambda x:x)\n",
    "\n",
    "    return transforms.Compose([\n",
    "        transforms.Lambda(denoise_fn),\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f509a275",
   "metadata": {},
   "source": [
    "### Preprocessing: Merge labels(**Only** execute the following cell if you haven't merge the folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1cda05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each list argument contains some subfolders, this function merge all images in subfolders into one big folder\n",
    "# list1: immune cells class\n",
    "# list2: non-invasive tumor\n",
    "# list3: invasive tumor\n",
    "def merge_folder(list1, list2, list3):\n",
    "    # define folder paths\n",
    "    source_path = './Images/100/'\n",
    "\n",
    "    immune_cells = list1\n",
    "\n",
    "    non_invasive_tumor = list2\n",
    "\n",
    "    invasive_tumor_cell = list3\n",
    "\n",
    "    folder_dests = [\"Immune_Cells\", \"Non_Invasive_Tumor\", \"Invasive_Tumor_Set\"]\n",
    "\n",
    "    # make empty folder\n",
    "    for i in folder_dests:\n",
    "        dest_path = source_path + i\n",
    "        os.makedirs(dest_path, exist_ok=True)\n",
    "        print(f\"{dest_path} is created.\")\n",
    "\n",
    "    # start copying file process\n",
    "    source_categories = [immune_cells, non_invasive_tumor, invasive_tumor_cell]\n",
    "    extensions = '*.png'\n",
    "\n",
    "    count = 1\n",
    "    cate_count = 0\n",
    "    for source_dirs in source_categories:\n",
    "        for src in source_dirs:\n",
    "            pattern = os.path.join(source_path+src, extensions)\n",
    "            print(pattern)\n",
    "            for img_path in glob.glob(pattern):\n",
    "                print(img_path)\n",
    "                filename = os.path.basename(img_path)\n",
    "                dest_path = source_path + folder_dests[cate_count]\n",
    "                file_dest_path = os.path.join(dest_path, filename)\n",
    "                # copying images from sub-folder to big folder, (overwirte if same images exist)\n",
    "                shutil.copy2(img_path, file_dest_path)\n",
    "                print(f'{count}: Copied {img_path} -> {file_dest_path}')\n",
    "                count += 1\n",
    "        cate_count += 1\n",
    "    return 0\n",
    "\n",
    "merge_folder(['B_Cells','CD4+_T_Cells'], ['DCIS_1', 'DCIS_2'], ['Invasive_Tumor', 'Prolif_Invasive_Tumor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4df20f2",
   "metadata": {},
   "source": [
    "### Define Image Dataset structure and image transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3b14e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataSet(Dataset):\n",
    "    def __init__(self, image_names, transform):\n",
    "        self.file_names = []\n",
    "        self.labels = []\n",
    "        for numeric_label, names in enumerate(image_names):\n",
    "            self.labels.extend([numeric_label]*len(names))\n",
    "            self.file_names.extend(names)\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.file_names[index]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "# labels = [\"B_Cells\", \"CD4+_T_Cells\", \"DCIS_1\", \"DCIS_2\", \"Invasive_Tumor\", \"Prolif_Invasive_Tumor\"]\n",
    "labels = [\"Immune_Cells\", \"Non_Invasive_Tumor\", \"Invasive_Tumor_Set\"]\n",
    "le = LabelEncoder()\n",
    "numeric_labels = le.fit_transform(labels)\n",
    "image_names = []\n",
    "for _ in numeric_labels:\n",
    "    image_names.append([])\n",
    "\n",
    "for (dir_path, dir_names, file_names) in os.walk(FOLDER_PATH):\n",
    "    parent_folder = os.path.basename(dir_path)\n",
    "    if parent_folder in labels: # Read the subset of dataset to reduce training time \n",
    "        for file in file_names:\n",
    "            image = cv2.imread(os.path.join(dir_path, file))\n",
    "            if image.shape[0] < 100 and image.shape[1] < 100: #skip the small image, it doesn't give much info\n",
    "                continue\n",
    "            numeric_label = le.transform([parent_folder])[0]\n",
    "            image_names[numeric_label].append(os.path.join(dir_path, file))\n",
    "\n",
    "\n",
    "denoising_datasets = {key : ImageDataSet(image_names, build_transform(key)) for key in denoise_methods.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0161227",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58d79a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #check if the computer has GPU\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(image_names))\n",
    "model = model.to(device)\n",
    "\n",
    "denoising_cnn_models = {key : deepcopy(model).to(device) for key in denoise_methods.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64124e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters setting\n",
    "num_epochs = 100\n",
    "patience = 10 #for early stopping\n",
    "batch_size = 128\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9806ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset: ImageDataSet):\n",
    "    train_idx, temp_idx = train_test_split(list(range(len(dataset))), test_size=0.3, random_state=0)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=0)\n",
    "\n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "    test_subset = Subset(dataset, test_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c1197a",
   "metadata": {},
   "source": [
    "### CNN Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afac9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss_curves = {key : [] for key in denoise_methods.keys()}\n",
    "val_loss_curves = {key : [] for key in denoise_methods.keys()}\n",
    "\n",
    "for denoise, model in denoising_cnn_models.items():\n",
    "    print(f\"Start training {denoise} model.\")\n",
    "    best_val_loss = float('inf')\n",
    "    epoch_no_improvement = 0\n",
    "    best_model_parameters = None\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_loader, val_loader, _ = split_dataset(denoising_datasets.get(denoise))\n",
    "    try:\n",
    "        scaler = torch.amp.GradScaler()\n",
    "        for epoch in range(num_epochs):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.amp.autocast(\"cuda\"):\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                # outputs = model(images)\n",
    "                # loss = criterion(outputs, labels)\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                # loss.backward()\n",
    "                # optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            training_loss = running_loss/len(train_loader)\n",
    "            training_loss_curves[denoise].append(training_loss)\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {training_loss:.4f}\")\n",
    "            \n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            avg_val_loss = val_loss/len(val_loader)\n",
    "            val_accuracy = 100 * correct / total\n",
    "            print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "            val_loss_curves[denoise].append(avg_val_loss)\n",
    "\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_model_parameters = model.state_dict()\n",
    "                epoch_no_improvement = 0\n",
    "            else:\n",
    "                epoch_no_improvement += 1\n",
    "                if epoch_no_improvement == patience:\n",
    "                    print(f\"No improvement for {patience} epoches. Early stopping.\")\n",
    "                    break\n",
    "\n",
    "        if best_model_parameters is not None:\n",
    "            model.load_state_dict(best_model_parameters)\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        # torch.save(model.state_dict(), f'CNN_{denoise}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a355b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for denoise, model in denoising_cnn_models.items():\n",
    "    torch.save(model.state_dict(), f'denoised_models/CNN_{denoise}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63e0dc9",
   "metadata": {},
   "source": [
    "### CNN models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2717325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for denoise, model in denoising_cnn_models.items():\n",
    "    _, _, test_loader = split_dataset(denoising_datasets.get(denoise))\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    end = time.time()\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    elapsed_time = end - start\n",
    "    \n",
    "    models_denoising_accuracies[\"CNN\"][denoise] = accuracy\n",
    "    models_denoising_f1_scores[\"CNN\"][denoise] = f1\n",
    "    models_denoising_confusion_metrics[\"CNN\"][denoise] = cm\n",
    "    models_denoising_classification_times[\"CNN\"][denoise] = elapsed_time\n",
    "    \n",
    "    print(f\"{denoise} accuracy: {accuracy}\")\n",
    "    print(f\"{denoise} f1 score: {f1}\")\n",
    "    print(f\"{denoise} classification time: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c113a538",
   "metadata": {},
   "source": [
    "### Feature extractor for traditional machine learning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc7d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_feature_extractor(model, dataset):\n",
    "    model.eval()\n",
    "    feature_extractor = nn.Sequential(*list(model.children())[:-1]) # remove the last layer\n",
    "    feature_extractor.eval()\n",
    "    feature_extractor.to(device)\n",
    "\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "    test_features = []\n",
    "    test_labels = []\n",
    "    train_loader, _, test_loader = split_dataset(dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            output = feature_extractor(images).squeeze()\n",
    "            train_features.append(output.cpu().numpy())\n",
    "            train_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    X_train = np.vstack(train_features)\n",
    "    y_train = np.hstack(train_labels)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            output = feature_extractor(images).squeeze()\n",
    "            test_features.append(output.cpu().numpy())\n",
    "            test_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    X_test = np.vstack(test_features)\n",
    "    y_test = np.hstack(test_labels)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8fb0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for denoise_method, dataset in denoising_datasets:\n",
    "    X_train, y_train, X_test, y_test = datasets_feature_extractor(model, dataset)\n",
    "\n",
    "    # SVM\n",
    "    svm = SVC()\n",
    "    start = time.time()\n",
    "    svm.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "\n",
    "    y_pred = svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    elapsed_time = end - start\n",
    "\n",
    "    models_denoising_accuracies[\"SVM\"][denoise_method] = accuracy\n",
    "    models_denoising_f1_scores[\"SVM\"][denoise_method] = f1\n",
    "    models_denoising_confusion_metrics[\"SVM\"][denoise_method] = cm\n",
    "    models_denoising_classification_times[\"SVM\"][denoise_method] = elapsed_time\n",
    "\n",
    "    print(f\"SVM {denoise_method} accuracy: {accuracy}\")\n",
    "    print(f\"SVM {denoise_method} f1 score: {f1}\")\n",
    "    print(f\"SVM {denoise_method} classification time: {elapsed_time}\")\n",
    "\n",
    "    #RF\n",
    "    rf = RandomForestClassifier()\n",
    "    start = time.time()\n",
    "    rf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    elapsed_time = end - start\n",
    "\n",
    "    models_denoising_accuracies[\"Random Forest\"][denoise_method] = accuracy\n",
    "    models_denoising_f1_scores[\"Random Forest\"][denoise_method] = f1\n",
    "    models_denoising_confusion_metrics[\"Random Forest\"][denoise_method] = cm\n",
    "    models_denoising_classification_times[\"Random Forest\"][denoise_method] = elapsed_time\n",
    "\n",
    "    print(f\"Random Forest {denoise_method} accuracy: {accuracy}\")\n",
    "    print(f\"Random Forest {denoise_method} f1 score: {f1}\")\n",
    "    print(f\"Random Forest {denoise_method} classification time: {elapsed_time}\")\n",
    "\n",
    "    #Find best k for KNN\n",
    "    knn_models = []\n",
    "    knn_accuracies = []\n",
    "    knn_f1_scores = []\n",
    "    knn_confusion_metrics = []\n",
    "    knn_classification_times = []\n",
    "    for k in range(1, 32, 2): #k = 1 to 31\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        start = time.time()\n",
    "        knn.fit(X_train, y_train)\n",
    "        end = time.time()\n",
    "\n",
    "        y_pred = knn.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        elapsed_time = end - start\n",
    "\n",
    "        knn_models.append(knn)\n",
    "        knn_accuracies.append(accuracy)\n",
    "        knn_f1_scores.append(f1)\n",
    "        knn_confusion_metrics.append(cm)\n",
    "        knn_classification_times.append(elapsed_time)\n",
    "\n",
    "    knn_accuracies = np.array(knn_accuracies)\n",
    "    max_idx = np.argmax(knn_accuracies)\n",
    "    best_k = 2*max_idx+1\n",
    "\n",
    "    print(f\"Best {best_k}NN {denoise_method} accuracy: {knn_accuracies[max_idx]}\")\n",
    "    print(f\"Best {best_k}NN {denoise_method} f1 score: {knn_f1_scores[max_idx]}\")\n",
    "    print(f\"Best {best_k}NN {denoise_method} classification time: {knn_classification_times[max_idx]}\")\n",
    "\n",
    "    accuracy = float(knn_accuracies[max_idx])\n",
    "    f1 = knn_f1_scores[max_idx]\n",
    "    cm = knn_confusion_metrics[max_idx]\n",
    "    elapsed_time = knn_classification_times[max_idx]\n",
    "\n",
    "    models_denoising_accuracies[\"KNN\"][denoise_method] = accuracy\n",
    "    models_denoising_f1_scores[\"KNN\"][denoise_method] = f1\n",
    "    models_denoising_confusion_metrics[\"KNN\"][denoise_method] = cm\n",
    "    models_denoising_classification_times[\"KNN\"][denoise_method] = elapsed_time\n",
    "\n",
    "    with open(f\"denoised_models/SVM_{denoise_method}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(svm, f)\n",
    "    with open(f\"denoised_models/RF_{denoise_method}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(rf, f)\n",
    "    with open(f\"denoised_models/{best_k}NN_{denoise_method}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(knn_models[max_idx], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc272ea",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818083cd",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a4ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(models_denoising_accuracies).T.reset_index().melt(id_vars='index', var_name='Denoising', value_name='Accuracy')\n",
    "df.columns = ['Model', 'Denoising', 'Accuracy']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=df, x='Model', y='Accuracy', hue='Denoising')\n",
    "\n",
    "plt.title('Accuracy by Model and Denoising Methods')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Model')\n",
    "plt.legend(title='Denoising Methods')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1804fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(models_denoising_f1_scores).T.reset_index().melt(id_vars='index', var_name='Denoising', value_name='Accuracy')\n",
    "df.columns = ['Model', 'Denoising', 'F1 Score']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=df, x='Model', y='F1 Score', hue='Denoising')\n",
    "\n",
    "plt.title('F1 Score by Model and Denoising Methods')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Model')\n",
    "plt.legend(title='Denoising Methods')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f0a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(models_denoising_classification_times).T.reset_index().melt(id_vars='index', var_name='Denoising', value_name='Accuracy')\n",
    "df.columns = ['Model', 'Denoising', 'Classification Time']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=df, x='Model', y='Classification Time', hue='Denoising')\n",
    "\n",
    "plt.title('Classification Time by Model and Denoising Methods')\n",
    "plt.ylabel('Classification Time')\n",
    "plt.xlabel('Model')\n",
    "plt.legend(title='Denoising Methods')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37786fa1",
   "metadata": {},
   "source": [
    "### Validation Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48b1249",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for denoise, val_losses in val_loss_curves:\n",
    "    plt.plot(val_losses, label=denoise)\n",
    "df = pd.DataFrame(val_loss_curves)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss Curve For each Denoiser')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef88e9d",
   "metadata": {},
   "source": [
    "### Confusion Matrix(How?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de76b696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
