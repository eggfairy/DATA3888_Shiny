{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f79481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from masking import centre_mask, non_centre_mask, random_mask\n",
    "import traceback\n",
    "\n",
    "#Turn all the randomisation off to ensure the results of every execution is the same \n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0763d6a",
   "metadata": {},
   "source": [
    "### Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254713fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "IMG_SIZE = 224\n",
    "FOLDER_PATH = \"Images/100\"\n",
    "\n",
    "masks = {\n",
    "    \"Centre\": centre_mask,\n",
    "    \"Non-centre\": non_centre_mask,\n",
    "    \"Random\": random_mask \n",
    "}\n",
    "\n",
    "classification_models = [\"CNN\", \"KNN\", \"SVM\", \"Random Forest\"]\n",
    "\n",
    "models_masks_accuracies = {model: {mask: -1 for mask in masks.keys()}  # -1 represent not yet calculated\n",
    "                               for model in classification_models}\n",
    "models_masks_f1_scores = {model: {mask: -1 for mask in masks.keys()}  # -1 represent not yet calculated\n",
    "                               for model in classification_models}\n",
    "models_masks_confusion_metrics = {model: {mask: -1 for mask in masks.keys()}  # -1 represent not yet calculated\n",
    "                               for model in classification_models}\n",
    "\n",
    "def build_transform(mask: str) -> transforms.Compose:\n",
    "    mask = masks.get(mask)\n",
    "\n",
    "    return transforms.Compose([\n",
    "        transforms.Lambda(mask),\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f435062e",
   "metadata": {},
   "source": [
    "### Define Image Dataset structure and image transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f23e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataSet(Dataset):\n",
    "    def __init__(self, image_names, transform):\n",
    "        self.file_names = []\n",
    "        self.labels = []\n",
    "        for numeric_label, names in enumerate(image_names):\n",
    "            self.labels.extend([numeric_label]*len(names))\n",
    "            self.file_names.extend(names)\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.file_names[index]\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "    \n",
    "\n",
    "labels = [\"Immune_Cells\", \"Non_Invasive_Tumor\", \"Invasive_Tumor_Set\"]\n",
    "le = LabelEncoder()\n",
    "numeric_labels = le.fit_transform(labels)\n",
    "image_names = []\n",
    "for _ in numeric_labels:\n",
    "    image_names.append([])\n",
    "\n",
    "for (dir_path, dir_names, file_names) in os.walk(FOLDER_PATH):\n",
    "    parent_folder = os.path.basename(dir_path)\n",
    "    if parent_folder in labels: # Read the subset of dataset to reduce training time \n",
    "        for file in file_names:\n",
    "            image = cv2.imread(os.path.join(dir_path, file))\n",
    "            if image.shape[0] < 100 and image.shape[1] < 100: #skip the small image, it doesn't give much info\n",
    "                continue\n",
    "            numeric_label = le.transform([parent_folder])[0]\n",
    "            image_names[numeric_label].append(os.path.join(dir_path, file))\n",
    "\n",
    "\n",
    "\n",
    "masking_datasets = {key : ImageDataSet(image_names, build_transform(key)) for key in masks.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee002ac",
   "metadata": {},
   "source": [
    "### CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2793c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #check if the computer has GPU\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(image_names))\n",
    "model = model.to(device)\n",
    "\n",
    "masking_cnn_models = {key : deepcopy(model).to(device) for key in masks.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db5afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters setting\n",
    "num_epochs = 100\n",
    "patience = 10 #for early stopping\n",
    "batch_size = 128\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05102108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset: ImageDataSet):\n",
    "    train_idx, temp_idx = train_test_split(list(range(len(dataset))), test_size=0.3, random_state=0)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=0)\n",
    "\n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "    test_subset = Subset(dataset, test_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0123f7d",
   "metadata": {},
   "source": [
    "### CNN Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b535e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss_curves = {key : [] for key in masks.keys()}\n",
    "val_loss_curves = {key : [] for key in masks.keys()}\n",
    "\n",
    "for mask, model in masking_cnn_models.items():\n",
    "    print(f\"Start training {mask} model.\")\n",
    "    best_val_loss = float('inf')\n",
    "    epoch_no_improvement = 0\n",
    "    best_model_parameters = None\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_loader, val_loader, _ = split_dataset(masking_datasets.get(mask))\n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                print(f\"Batch loss: {loss}\")\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            training_loss = running_loss/len(train_loader)\n",
    "            training_loss_curves[mask].append(training_loss)\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {training_loss:.4f}\")\n",
    "            \n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            avg_val_loss = val_loss/len(val_loader)\n",
    "            val_accuracy = 100 * correct / total\n",
    "            print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "            val_loss_curves[mask].append(avg_val_loss)\n",
    "\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_model_parameters = model.state_dict()\n",
    "                epoch_no_improvement = 0\n",
    "            else:\n",
    "                epoch_no_improvement += 1\n",
    "                if epoch_no_improvement == patience:\n",
    "                    print(f\"No improvement for {patience} epoches. Early stopping.\")\n",
    "                    break\n",
    "\n",
    "        if best_model_parameters is not None:\n",
    "            model.load_state_dict(best_model_parameters)\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa6fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask, model in masking_cnn_models.items():\n",
    "    torch.save(model.state_dict(), f'masking_models/CNN_{mask}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8a8773",
   "metadata": {},
   "source": [
    "### CNN models evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5a5b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask, model in masking_cnn_models.items():\n",
    "    _, _, test_loader = split_dataset(masking_datasets.get(mask))\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    models_masks_accuracies[\"CNN\"][mask] = accuracy\n",
    "    models_masks_f1_scores[\"CNN\"][mask] = f1\n",
    "    models_masks_confusion_metrics[\"CNN\"][mask] = cm\n",
    "    \n",
    "    print(f\"{mask} accuracy: {accuracy}\")\n",
    "    print(f\"{mask} f1 score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_feature_extractor(model, dataset):\n",
    "    model.eval()\n",
    "    feature_extractor = nn.Sequential(*list(model.children())[:-1]) # remove the last layer\n",
    "    feature_extractor.eval()\n",
    "    feature_extractor.to(device)\n",
    "\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "    test_features = []\n",
    "    test_labels = []\n",
    "    train_loader, _, test_loader = split_dataset(dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            output = feature_extractor(images).squeeze()\n",
    "            train_features.append(output.cpu().numpy())\n",
    "            train_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    X_train = np.vstack(train_features)\n",
    "    y_train = np.hstack(train_labels)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            output = feature_extractor(images).squeeze()\n",
    "            test_features.append(output.cpu().numpy())\n",
    "            test_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    X_test = np.vstack(test_features)\n",
    "    y_test = np.hstack(test_labels)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc2b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for denoise_method, dataset in masking_datasets:\n",
    "    X_train, y_train, X_test, y_test = datasets_feature_extractor(model, dataset)\n",
    "\n",
    "    # SVM\n",
    "    svm = SVC()\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    models_masks_accuracies[\"SVM\"][denoise_method] = accuracy\n",
    "    models_masks_f1_scores[\"SVM\"][denoise_method] = f1\n",
    "    models_masks_confusion_metrics[\"SVM\"][denoise_method] = cm\n",
    "\n",
    "    print(f\"SVM {denoise_method} accuracy: {accuracy}\")\n",
    "    print(f\"SVM {denoise_method} f1 score: {f1}\")\n",
    "\n",
    "    #RF\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    models_masks_accuracies[\"Random Forest\"][denoise_method] = accuracy\n",
    "    models_masks_f1_scores[\"Random Forest\"][denoise_method] = f1\n",
    "    models_masks_confusion_metrics[\"Random Forest\"][denoise_method] = cm\n",
    "\n",
    "    print(f\"Random Forest {denoise_method} accuracy: {accuracy}\")\n",
    "    print(f\"Random Forest {denoise_method} f1 score: {f1}\")\n",
    "    print(f\"Random Forest {denoise_method} classification time: {elapsed_time}\")\n",
    "\n",
    "    #Find best k for KNN\n",
    "    knn_models = []\n",
    "    knn_accuracies = []\n",
    "    knn_f1_scores = []\n",
    "    knn_confusion_metrics = []\n",
    "    for k in range(1, 32, 2): #k = 1 to 31\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = knn.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        knn_models.append(knn)\n",
    "        knn_accuracies.append(accuracy)\n",
    "        knn_f1_scores.append(f1)\n",
    "        knn_confusion_metrics.append(cm)\n",
    "\n",
    "    knn_accuracies = np.array(knn_accuracies)\n",
    "    max_idx = np.argmax(knn_accuracies)\n",
    "    best_k = 2*max_idx+1\n",
    "\n",
    "    print(f\"Best {best_k}NN {denoise_method} accuracy: {knn_accuracies[max_idx]}\")\n",
    "    print(f\"Best {best_k}NN {denoise_method} f1 score: {knn_f1_scores[max_idx]}\")\n",
    "\n",
    "    accuracy = float(knn_accuracies[max_idx])\n",
    "    f1 = knn_f1_scores[max_idx]\n",
    "    cm = knn_confusion_metrics[max_idx]\n",
    "\n",
    "    models_masks_accuracies[\"KNN\"][denoise_method] = accuracy\n",
    "    models_masks_f1_scores[\"KNN\"][denoise_method] = f1\n",
    "    models_masks_confusion_metrics[\"KNN\"][denoise_method] = cm\n",
    "\n",
    "    with open(f\"denoised_models/SVM_{denoise_method}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(svm, f)\n",
    "    with open(f\"denoised_models/RF_{denoise_method}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(rf, f)\n",
    "    with open(f\"denoised_models/{best_k}NN_{denoise_method}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(knn_models[max_idx], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210ede0a",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5882bf",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a582a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(models_masks_accuracies).T.reset_index().melt(id_vars='index', var_name='Mask', value_name='Accuracy')\n",
    "df.columns = ['Model', 'Mask', 'Accuracy']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=df, x='Model', y='Accuracy', hue='Mask')\n",
    "\n",
    "plt.title('Accuracy by Model and Mask Methods')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Model')\n",
    "plt.legend(title='Masks')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0439c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(models_masks_f1_scores).T.reset_index().melt(id_vars='index', var_name='Mask', value_name='F1 Score')\n",
    "df.columns = ['Model', 'Mask', 'F1 Score']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=df, x='Model', y='F1 Score', hue='Mask')\n",
    "\n",
    "plt.title('F1 Score by Model and Mask Methods')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Model')\n",
    "plt.legend(title='Masks')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1defe4f5",
   "metadata": {},
   "source": [
    "### Validation Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596deb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for denoise, val_losses in val_loss_curves:\n",
    "    plt.plot(val_losses, label=denoise)\n",
    "df = pd.DataFrame(val_loss_curves)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss Curve For each Denoiser')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
